\section{Definition of Vector Space}

\begin{exercise}
    Prove that $-(-v) = v$ for every $v \in V$.\\
\end{exercise}

\begin{solution}
    \\ Let $v \in V$, by definition, we know that by definition, $-v$ is defined as the only vector in $V$ satisfying
    $$v + (-v) = 0$$
    which is equivalent to
    $$(-v) + v = 0$$ 
    by commutativity of addition in $V$. However, notice that by definition, $-(-v)$ is the unique vector satisfying
    $$(-v) + [-(-v)] = 0$$
    But since $v$ itself also satisfies this equation, we get $-(-v) = v$ by uniqueness.\\
\end{solution}

\begin{exercise}
    Suppose $a \in \F$, $v \in V$, and $av = 0$. Prove that $a = 0$ or $v = 0$.\\
\end{exercise}

\begin{solution}
    \\ Suppose that $a \neq 0$, then by properties of $\F$, the inverse $a^{-1}$ exists. Hence, if we multiply by $a^{-1}$ on both sides, we get
    \begin{align*}
        av = 0 &\implies a^{-1}(av) = a^{-1}0 \\
        &\implies (a^{-1}a)v = 0 \\
        &\implies 1v = 0 \\
        &\implies v = 0
    \end{align*}
    Therefore, we either have $a = 0$ or $v = 0$.\\
\end{solution}

\begin{exercise}
    Suppose $v, w \in V$. Explain why there exists a unique $x \in V$ such that $v + 3x = w$.\\
\end{exercise}

\begin{solution}
    \\ By properties of vector spaces, since $v \in V$, then $-v \in V$. Similarly, since $w$ and $-v$ are in $V$, then $w + (-v) \in V$. Finally, since $w + (-v) \in V$, then $3^{-1}(w + (-v)) \in V$. Thus, define $x_0$ as the vector $3^{-1}(w + (-v))$ in $V$. Notice that
    \begin{align*}
        v + 3x_0 &= v + 3[3^{-1}(w + (-v))] \\
        &= v + (3 \cdot 3^{-1})(w + (-v)) \\
        &= v + 1(w + (-v)) \\
        &= v + (w + (-v)) \\
        &= v + ((-v) + w) \\
        &= (v + (-v)) + w \\
        &= 0 + w \\
        &= w
    \end{align*}
    which shows that the equation has at least one solution. To prove uniqueness, let $x_1 \in V$ be an arbitrary solution to the equation, then we get
    \begin{align*}
        v + 3x_1 = w &\implies (-v) + (v + 3x_1) = (-v) + w \\
        &\implies ((-v) + v) + 3x_1 = w + (-v) \\
        &\implies 0 + 3x_1 = w + (-v) \\
        &\implies 3x_1 = w + (-v) \\
        &\implies 3^{-1}(3x_1) = 3^{-1}(w + (-v)) \\
        &\implies (3^{-1}3)x_1 = x_0 \\
        &\implies 1x_1 = x_0 \\
        &\implies x_1 = x_0
    \end{align*} 
    which proves that $x_0$ is the unique solution to the equation. \\
\end{solution}

\begin{exercise}
    The empty set is not a vector space. The empty set fails to satisfy only one of the requirements listed in the definition of a vector space. Which one? \\
\end{exercise}

\begin{solution}
    \\ The empty set doesn't satisfy the axiom that states that there must be an additive identity since the empty set is empty by definition.\\
\end{solution}

\begin{exercise}
    Show that in the definition of a vector space, the additive inverse condition can be replaced with the condition that
    $$0v = 0 \text{ for all } v\in V.$$
    Here, the 0 on the left side is the number 0, and the 0 on the right side is the additive identity of $V$.\\
\end{exercise}

\begin{solution}
    \\ We already know that the axioms of a vector space imply that $0v = 0$ for all $v \in V$. Hence, it suffices to prove that if we assume the axioms of a vector space without the additive inverse condition, then we can prove the additive inverse condition if we also assume the property that $0v = 0$ for all $v \in V$. Let $v \in V$, the by the distributive condition, we get
    \begin{align*}
        0v = 0 &\implies (1 + (-1))v = 0 \\
        &\implies 1v + (-1)v = 0 \\
        &\implies v + (-1)v = 0
    \end{align*}
    which proves that $v$ has an additive inverse for all $v \in V$.\\
\end{solution}

\begin{exercise}
    Let $\infty$ and $-\infty$ denote two distinct objects, neither of which is in $\R$. Define an addition and scalar multiplication on $\R \cup \{\infty, -\infty\}$ as you could guess from the notation. Specifically, the sum and product of two reals numbers is as usual, and for $t \in \R$ define 
    $$t\infty = \begin{cases}
        - \infty & \text{if } t < 0,\\
        0 & \text{if } t = 0,\\
        \infty & \text{if } t>0,
    \end{cases} \qquad t(-\infty) = \begin{cases}
        \infty & \text{if } t < 0,\\
        0 & \text{if } t = 0,\\
        -\infty & \text{if } t>0,
    \end{cases}$$
    and
    \begin{align*}
        t + \infty &= \infty + t = \infty + \infty = \infty \\
        t + (-\infty) &= (-\infty) + t = (-\infty) + (-\infty) = -\infty \\
        \infty + (-\infty) &= (-\infty) + \infty = 0
    \end{align*}
    With these operations of addition and scalar multiplication, is $\R \cup \{\infty, -\infty\}$ a vector space over $\R$? Explain. \\
\end{exercise}

\begin{solution}
    \\ With these operations of addition and scalar multiplication, $\R \cup \{\infty, -\infty\}$ cannot be a vector space since
    $$((-\infty) + \infty) + \infty = 0 + \infty = \infty$$
    and
    $$(-\infty) + (\infty + \infty) = (-\infty) + \infty = 0$$
    which proves that addition isn't associative under this operation. \\
\end{solution}

\begin{exercise}
    Suppose $S$ is a nonempty set. Let $V^S$ denote the set of functions from $S$ to $V$. Define a natural addition and scalar multiplication on $V^S$, and show that $V^S$ is a vector space with these definitions. \\
\end{exercise}

\begin{solution}
    \\ For any $f$ and $g$ in $V^S$, define $f + g : S \to V$ by $s \mapsto f(s) + g(s)$ for all $s \in S$. Similarly, for all $\alpha \in \F$ and $f \in V^S$, define $\alpha f : S \to V$ by $s \mapsto \lambda f(s)$ for all $s \in S$. With these definitions, let's prove that $V^S$ is a vector space.
    \begin{itemize}
        \item (\textbf{commutativity}) Let $f, g \in V^S$, let's show that $f + g = g + f$. Let $s \in S$, then by commutativity in $V$, we obviously have
        $$(f+g)(s) = f(s) + g(s) = g(s) + f(s) = (g+f)(s)$$
        Since it holds for all $s$, then $f + g = g + f$.
        \item (\textbf{associativity}) Let $f,g,h \in V^S$ and $s \in S$, then by associativity in $V$, we have
        \begin{align*}
            [(f+g)+h](s) &= (f+g)(s) + h(s) \\
            &= [f(s) + g(s)] + h(s) \\
            &= f(s) + [g(s) + h(s)] \\
            &= f(s) + (g+h)(s) \\
            &= [f + (g+h)](s)
        \end{align*}
        Since it holds for all $s \in S$, then $(f+g) + h= f + (g+h)$. \\
        Let now $f \in V^S$, $a,b \in \F$ and $s \in S$, then by associativity in $V$, we get:
        \begin{align*}
            [(ab)f](s) &= (ab)f(s) \\
            &= a(bf(s)) \\
            &= a(bf)(s) \\
            &= [a(bf)](s)
        \end{align*}
        Since it holds for all $s \in S$, then $(ab)f = a(bf)$.
        \item (\textbf{additive identity}) Let's denote by $0_{V^S}$ the zero function in $V^S$, then for all $f \in V^S$ and $s \in S$, we have
        $$(f+0_{V^S})(s) = f(s) + 0_{V^S}(s) = f(s) + 0 = f(s)$$
        Since it holds for all $s \in S$, then $f + 0_{V^S} = f$ for all $f \in V^S$.
        \item (\textbf{additive inverse}) Again, let's denote by $0_{V^S}$ the zero function in $V^S$, then for all $f \in V^S$, we can define the function $g = (-1)f \in V^S$. Hence, for all $s \in S$, we get
        \begin{align*}
            (f + g)(s) &= f(s) + g(s) \\
            &= f(s) + (-1)f(s) \\
            &= f(s) + (-f(s)) \\
            &= 0 \\
            &= 0_{V^S}(s)
        \end{align*}
        Since it holds for all $s \in S$, then $f + g = 0_{V^S}$.
        \item (\textbf{multiplicative identity}) Let $f \in V^S$, then for all $s \in S$, we have
        $$(1 f)(s) = 1 f(s) = f(s)$$
        Since it holds for all $s \in S$, then $1f = f$.
        \item (\textbf{distributive property}) Let $f,g \in V^S$, $a \in \F$ and $s \in S$, then
        \begin{align*}
            [a(f+g)](s) &= a(f+g)(s) \\
            &= a(f(s) + g(s)) \\
            &= a f(s) + ag(s) \\
            &= (af)(s) + (ag)(s) \\
            &= (af + ag)(s)
        \end{align*}
        Since it holds for all $s \in S$, then $a(f+g) = af + ag$. Similarly, for all $f \in V^S$, $a,b \in \F$ and $s \in S$, we have
        \begin{align*}
            [(a+b)f](s) &= (a+b)f(s) \\
            &= af(s) + bf(s) \\
            &= (af)(s) + (bf)(s) \\
            &= (af + bf)(s)
        \end{align*}
        Since it holds for all $s \in S$, then $(a+b)f = af + bf$.
    \end{itemize}
    Therefore, $V^S$ is a vector space under these definitions.\\
\end{solution}

\begin{exercise}
    Suppose $V$ is a real vector space.
    \begin{itemize}
        \item The \textit{complexification} of $V$, denoted by $V_{\C}$, equals $V \times V$. An element of $V_{\C}$ is an ordered pair $(u,v)$, where $u,v \in V$, but we write this as $u+iv$.
        \item Addition on $V_{\C}$ is defined by
        $$(u_1+iv_1) + (u_2 + iv_2) = (u_1 + u_2) + i(v_1 + v_2)$$
        for all $u_1, v_1, u_2, v_2 \in V$.
        \item Complex scalar multiplication on $V_{\C}$ is defined by 
        $$(a+ib)(u+iv) = (au - bv) + i(av + bu)$$
        for all $a,b \in \R$ and all $u,v\in V$.
    \end{itemize}
    Prove that with these definitions of addition and scalar multiplication as above, $V_{\C}$ is a complex vector space.\\
\end{exercise}

\begin{solution}
    \begin{itemize}
        \item (\textbf{commutativity}) Let $u_1, v_1, u_2, v_2 \in V$, then by commutativity in $V$, we have
        \begin{align*}
            (u_1+iv_1) + (u_2 + iv_2) &= (u_1 + u_2) + i(v_1 + v_2) \\
            &= (u_2 + u_1) + i(v_2 + v_1) \\
            &= (u_2+iv_2) + (u_1 + iv_1)
        \end{align*}
        which proves that addition is commutative.
        \item (\textbf{associativity}) Let $u_1, v_1, u_2, v_2, u_3,v_3 \in V$, then by associativity in $V$, we have
        \begin{align*}
            [(u_1+iv_1) + (u_2 + iv_2)] + (u_3+iv_3) &= [(u_1 + u_2) + i(v_1 + v_2)] + (u_3+iv_3) \\
            &= ([u_1 + u_2] + u_3) + i([v_1 + v_2] + v_3) \\
            &= (u_1 + [u_2 + u_3]) + i(v_1 + [v_2 + v_3]) \\
            &= (u_1 + iv_1) + [(u_2 + u_3) + i(v_2 + v_3)] \\
            &= (u_1 + iv_1) + [(u_2 + iv_2) + (u_3 + iv_3)]
        \end{align*}
        Let now $a,b,c,d \in \R$ and $u,v \in V$, then we get:
        \begin{align*}
            [(a+bi)(c+di)]&(u+iv) \\ 
            &= [(ac - bd) + i(ad + bc)](u+iv) \\
            &= [(ac - bd)u - (ad+bc)v] + i [(ac - bd)v + (ad+bc)u] \\
            &= [acu - bdu - adv -bcv] + i [acv - bdv + adu+bcu] \\
            &= [a(cu - dv) - b(cv + du)] + i[a(cv + du) + b(cu - dv)] \\
            &= (a+ib)[(cu - dv)+i(cv+du)] \\
            &= (a+ib)[(c+id)(u+iv)]
        \end{align*}
        which proves the associativity condition.
        \item (\textbf{additive identity}) For all $u,v \in V$,
        $$(u + iv) + (0+i0) = (u+0) + i(v+0) = u + iv$$
        which proves that $0+i0$ is an additive identity.
        \item (\textbf{additive inverse}) Let $u,v \in V$, then since $(-u), (-v) \in V$, we get
        $$(u+iv) + ([-u] + i[-v]) = (u + [-u]) + i(v + [-v]) = 0 + i0$$
        which proves that every element has an additive inverse.
        \item (\textbf{multiplicative identity}) Let $u,v \in V$, then
        $$(1 + i0)(u +iv) = (1u - 0v) + i(1v + 0u) = u + iv$$
        which proves that $1 = 1 + i0$ is a multiplicative identity.
        \item (\textbf{distributive property}) Let $a,b \in \R$ and $u_1, v_1, u_2, v_2 \in V$, then
        \begin{align*}
            (a+ib)[(u_1 + i&v_1) + (u_2 + iv_2)] \\
            &= (a+ib)([u_1 + u_2] + i[v_1 + v_2]) \\
            &= (a[u_1 + u_2] - b[v_1 + v_2]) + i(a[v_1 + v_2] + b[u_1 + u_2]) \\
            &= (au_1 + au_2 - bv_1 - bv_2) + i(av_1 + av_2 + v_1 + bv_2) \\
            &= ([au_1 - bv_1] + [au_2 - bv_2]) + i([av_1 + bu_1] + [av_2 + bu_1]) \\
            &= [(au_1 - bv_1) + i(av_1 + bu_1)] + [(au_2 - bv_2) + i(av_2 + bu_2)] \\
            &= [(a+ib)(u_1 + iv_1)] + [(a+ib)(u_2 + iv_2)]
        \end{align*}
        Similarly, for all $a,b,c,d \in \R$, and $u,v \in \R$, we have
        \begin{align*}
            [(a+ib) + (c+&id)](u+iv)\\
            &= ([a+c] + i[b+d])(u+iv) \\
            &= ([a+c]u - [b+d]v) + i([a+c]v + [b+d]u) \\
            &= (au + cu -bv -dv) + i(av + cv + bu+du) \\
            &= ([au - bv] + [cu - dv]) + i([av + bu] + [cv + du]) \\
            &= [(au - bv) + i(av + bu)] + [(cu - dv) + i(cv + du)] \\
            &= (a+ib)(u+iv) + (c+id)(u+iv)
        \end{align*}
        which proves the distributive property.
    \end{itemize}
    Therefore, $V_{\C}$ is a vector space under these definitions.
\end{solution}