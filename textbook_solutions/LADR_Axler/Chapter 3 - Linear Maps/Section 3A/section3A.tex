\chapter{Linear Maps}

\section{Vector Space of Linear Maps}

\begin{exercise}
    Suppose $b,c \in \R$. Define $T: \R^3 \to \R^2$ by
    $$T(x,y,z) = (2x-4y + 3z + b, 6x + cxyz).$$
    Show that $T$ is linear if and only if $b = c = 0$. \\
\end{exercise}

\begin{solution}
    \\ ($\implies$) Suppose that $T$ is linear, then we know from Proposition 3.10 that $T0 = 0$. Thus, it follows that
    $$T(0,0,0) = (b, 0) = (0,0)$$
    which implies that $b = 0$. To prove that $c = 0$, notice that by linearity of $T$, we have
    $$T(2,2,2) = 2T(1,1,1).$$
    If we plug-in the values into the definition of $T$, we get
    $$(4 - 8 + 6 + 0, 12 + 8c) = 2(2 - 4 + 3 + 0, 6 + c)$$
    which is equivalent to
    $$(2, 12 + 8c) = (2, 12 + 2c).$$
    It follows that $12 + 8c = 12 + 2c$ which can only be true when $c = 0$. Thus, $b = c = 0$. \\
    $( \ \Longleftarrow \ )$ Suppose now that $b = c = 0$, then $T(x,y,z)$ becomes
    $$T(x,y,z) = (2x-4y + 3z, 6x)$$
    for all $x,y,z \in \R$. Let's show that $T$ is linear. First, take $(x,y,z), (x',y',z') \in \R^3$ and notice that
    \begin{align*}
        T((x,y,z) + (x',y',z')) &= T(x+x', y+y', z+z') \\
        &= (2(x + x')-4(y+y') + 3(z+z'), 6(x+x')) \\
        &= (2x - 4y + 3z + 2x' - 4y' + 3z', 6x + 6x') \\
        &= (2x-4y + 3z, 6x) + (2x'-4y' + 3z', 6x') \\
        &= T(x,y,z) + T(x',y',z')
    \end{align*}
    Moreover, given any $\lambda \in \R$ and $(x,y,z) \in \R^3$, we have
    \begin{align*}
        T(\lambda(x,y,z)) &= T(\lambda x, \lambda y, \lambda z) \\
        &= (2(\lambda x)-4(\lambda y) + 3(\lambda z), 6(\lambda x)) \\
        &= (\lambda(2x - 4y + 3z), \lambda(6x)) \\
        &= \lambda(2x - 4y + 3z, 6x) \\
        &= \lambda T(x,y,z)
    \end{align*}
    Therefore, $T$ is linear.\\
\end{solution}

\begin{exercise}
    Suppose $b,c \in \R$. Define $T : \mathcal{P}(\R) \to \R^2$ by
    $$Tp = \left(3p(4) + 5p'(6) + bp(1)p(2), \int_{-1}^{2}x^3p(x)dx + c \sin p(0) \right).$$
    Show that $T$ is linear if and only if $b = c = 0$. \\
\end{exercise}

\begin{solution}
    \\ ($\implies$) Suppose that $T$ is linear, then if we let $p$ be the constant polynomial equal to $\pi/2$, we get that $T$ must satisfy
    $$T(2p) = 2Tp.$$
    If we rewrite this using the definition of $T$ and $p$, we obtain
    $$\left(3\pi + b\pi^2, \pi\int_{-1}^{2}x^3dx + c\sin(\pi)\right) = 2\left(3\frac{\pi}{2} + b\frac{\pi^2}{4}, \frac{\pi}{2}\int_{-1}^{2}x^3dx + c\sin\left(\frac{\pi}{2}\right)\right)$$
    which can be simplified to
    $$\left(3\pi + b\pi^2, \pi\int_{-1}^{2}x^3dx\right) = \left(3\pi + b\frac{\pi^2}{2}, \pi\int_{-1}^{2}x^3dx + c\right).$$
    This gives us the following system of equations:
    $$\begin{cases}
        3\pi + b\pi^2 = 3\pi + b\frac{\pi^2}{2} \\
        \pi\int_{-1}^{2}x^3dx = \pi\int_{-1}^{2}x^3dx + c
    \end{cases} 
    \implies
    \begin{cases}
        b = \frac{1}{2}b \\
        c = 0
    \end{cases}
    \implies b = c = 0.$$
    $( \ \Longleftarrow \ )$ Suppose that $b = c = 0$, then for all $p \in \mathcal{P}(\R)$, we have
    $$Tp = \left(3p(4) + 5p'(6), \int_{-1}^{2}x^3p(x)dx \right).$$
    Thus, for any $p_1, p_2 \in \mathcal{P}(\R)$, we get 
    \begin{align*}
        T(p_1 + p_2) &= \left(3(p_1 + p_2)(4) + 5(p_1 + p_2)'(6), \int_{-1}^{2}x^3(p_1 + p_2)(x)dx \right) \\
        &= \left(3(p_1(4) + p_2(4)) + 5(p_1'(6) + p_2'(6)), \int_{-1}^{2}x^3(p_1(x) + p_2(x))dx \right) \\
        &= \left(3p_1(4) + 3p_2(4) + 5p_1'(6) + 5p_2'(6), \int_{-1}^{2}x^3p_1(x)dx + \int_{-1}^{2}x^3p_2(x)dx \right) \\
        &= \left(3p_1(4) + 5p_1'(6), \int_{-1}^{2}x^3p_1(x)dx \right) + \left(3p_2(4) + 5p_2'(6), \int_{-1}^{2}x^3p_2(x)dx \right) \\
        &= Tp_1 + Tp_2.
    \end{align*}
    Similarly, for all $\lambda \in \R$ and $p \in \mathcal{P}(\R)$, we have
    \begin{align*}
        T(\lambda p) &= \left(3(\lambda p)(4) + 5(\lambda p)'(6), \int_{-1}^{2}x^3(\lambda p)(x)dx \right) \\
        &= \left(3\lambda p(4) + 5\lambda p'(6), \int_{-1}^{2}x^3 \lambda p(x)dx \right) \\
        &= \left(\lambda (3p(4) + 5p'(6)), \lambda\int_{-1}^{2}x^3 p(x)dx \right) \\
        &= \lambda \left(3p(4) + 5p'(6), \int_{-1}^{2}x^3 p(x)dx \right) \\
        &= \lambda Tp.
    \end{align*}
    Therefore, $T$ is linear. \\
\end{solution}

\begin{exercise}
    Suppose that $T \in \L(\F^n, \F^m)$. Show that there exist scalars $A_{j,k} \in \F$ for $j = 1, ..., m$ and $k= 1, ..., n$ such that 
    $$T(x_1, ..., x_n) = (A_{1,1}x_1 + \dots + A_{1,n}x_n, ..., A_{m,1}x_1 + \dots + A_{m,n}x_n)$$
    for every $(x_1, ..., x_n) \in \F^n$. \\
\end{exercise}

\begin{solution}
    \\ Denote by $e_1, ..., e_n$ the standard basis of $\F^n$ and by $f_1, ..., f_m$ the standard basis for $\F^m$, then for all $k \in \{1, ..., n\}$, there exist scalars $A_{1,k}, ..., A_{m,k} \in \F$ such that
    $$Te_k = A_{1,k}f_1 + \dots + A_{m,k}f_m.$$
    Therefore, by linearity, for all $(x_1, ..., x_n) \in \F^n$:
    \begin{align*}
        T(x_1, ..., x_n) &= x_1Te_1 + \dots + x_n Te_n \\
        &= x_1(A_{1,1}f_1 + \dots + A_{m,1}f_m) + \dots + x_n(A_{1,n}f_1 + \dots + A_{m,n}f_m) \\
        &= (A_{1,1}x_1 + \dots + A_{1,n}x_n)f_1 + \dots + (A_{m,1}x_1 + \dots + A_{m,n}x_n)f_m \\
        &= (A_{1,1}x_1 + \dots + A_{1,n}x_n, ..., A_{m,1}x_1 + \dots + A_{m,n}x_n).
    \end{align*}
    Therefore, any linear transformation has this form. \\
\end{solution}

\begin{exercise}
    Suppose $T \in \L(V, W)$ and $v_1, ..., v_m$ is a list of vectors in $V$ such that $Tv_1, ..., Tv_m$ is a linearly independent list in $W$. Prove that $v_1, ..., v_m$ is linearly independent. \\
\end{exercise}

\begin{solution}
    \\ To prove that $v_1, ..., v_m$ is linearly independent, take arbitrary scalars $\alpha_1, ..., \alpha_m \in \F$ such that
    $$\alpha_1 v_1 + ... + \alpha_m v_m = 0.$$
    By evaluating on both sides by $T$, we get by linearity of $T$ the following equation:
    $$\alpha_1 Tv_1 + ... + \alpha_m Tv_m = 0.$$
    But since the list $Tv_1, ..., Tv_m$ is a linearly independent in $W$, then 
    $$\alpha_1 = ... = \alpha_m = 0$$
    which proves that $v_1, ..., v_m$ is linearly independent. \\
\end{solution}

\begin{exercise}
    Prove that $\L(V, W)$ is a vector space, as was asserted in 3.6. \\
\end{exercise}

\begin{solution}
    \\ We already proved in Section 1B Exercise 7 that for any nonempty set $S$ and vector space $U$, the set $U^S$ equipped with the usual addition and scalar multiplication is a vector space. Hence, if we let $S = V$ and $U = W$, we already know that the set of functions from $V$ tp $W$ is a vector space. Since $\L(V, W) \subset W^V$, then it suffices to show that $\L(V, W)$ is a subspace. \\
    First, notice that $\L(V, W)$ is non-empty since it contains the additive identity map: the constant zero map is linear. Given two linear maps $T_1, T_2 \in \L(V, W)$, we can show that $T_1 + T_2 \in \L(V, W)$ by proving that it is a linear map from $V$ to $W$. Hence, take arbitrary $x,y \in V$ and $\lambda \in \F$ to get:
    \begin{align*}
        (T_1 + T_2)(x + y) &= T_1(x + y) + T_2(x + y) \\
        &= T_1(x) + T_1(y) + T_2(x) + T_2(y) \\
        &= (T_1 + T_2)(x) + (T_1 + T_2)(y),
    \end{align*}
    and
    \begin{align*}
        (T_1 + T_2)(\lambda x) &= T_1(\lambda x) + T_2(\lambda x) \\
        &= \lambda T_1(x) + \lambda T_2(x) \\
        &= \lambda (T_1(x) + T_2(x)) \\
        &= \lambda (T_1 + T_2)(x).
    \end{align*}
    Thus, $\L(V, W)$ is closed under addition. Similarly, given a linear map $T \in \L(V, W)$ and $\alpha \in \F$, we get that $\alpha T \in \L(V, W)$ because for all $x,y \in V$ and $\lambda \in \F$, we have the following:
    \begin{align*}
        (\alpha T)(x + y) &= \alpha T(x + y) \\
        &= \alpha (T(x) + T(y)) \\
        &= \alpha T(x) + \alpha T(y) \\
        &= (\alpha T)(x) + (\alpha T)(y)
    \end{align*}
    and
    \begin{align*}
        (\alpha T)(\lambda x) &= \alpha T(\lambda x) \\
        &= \alpha \lambda T(x) \\
        &= \lambda \alpha T(x) \\
        &= \lambda (\alpha T)(x).
    \end{align*}
    Therefore, $\L(V, W)$ is a vector space since it is a subspace of $W^V$. \\
\end{solution}

\begin{exercise}
    Prove that the multiplication of linear maps has the associative, identity and distributive properties asserted in 3.8. \\
\end{exercise}

\begin{solution}
    \vspace{-0.25cm}
    \begin{itemize}
        \item (Associativity) Let $V_1, V_2, V_3, V_4$ be vector spaces and $T_1 : V_1 \to V_2$, $T_2 : V_2 \to V_3$ and $T_3 : V_3 \to V_4$ be linear maps. Associativity follows from the fact that for all $x \in V_1$:
        \begin{align*}
            ((T_1 T_2)T_3)(x) &= (T_1 T_2)(T_3(x)) \\
            &= T_1(T_2(T_3(x))) \\
            &= T_1(T_2T_3(x)) \\
            &= (T_1(T_2T_3))(x).
        \end{align*}
        Since it holds for all $x \in X$, then $(T_1 T_2)T_3 = T_1(T_2T_3)$.
        \item (Identity) Let $V$ and $W$ be vector space. Consider the identity map $I_V : V \to W$ and let's show that it is indeed linear. For all $x,y \in V$:
        $$I_V(x + y) = x + y = I_V(x) + I_V(y)$$
        and for any $\lambda \in \F$ and $x \in V$:
        $$I_V(\lambda x) = \lambda x = \lambda I_V(x).$$
        Therefore, $I_V$ is linear. To prove that it is the multiplicative identity in $\L(V,W)$, let $T: V \to W$ be a linear map and $x \in V$, then
        $$(I_V T)(x) = I_V(Tx) = Tx$$
        and
        $$(TI_V)(x) = T(I_Vx) = Tx$$
        so $I_V T = T I_V = T$ for all linear maps $T \in \L(V,W)$.
        \item (Distributivity 1) Let $U,V,W$ be vector spaces, $S_1, S_2 \in \L(V,W)$ and $T \in \L(U,V)$, then for all $x \in V$, we have
        \begin{align*}
            [(S_1 + S_2)T](x) &= (S_1 + S_2)(Tx) \\
            &= S_1(Tx) + S_2(Tx) \\
            &= (S_1 T)(x) + (S_2 T)(x) \\
            &= [S_1 T + S_2 T](x).
        \end{align*}
        Since it holds for all $x \in U$, then $(S_1 + S_2) T = S_1 T  + S_2 T$.
        \item (Distributivity 2) Let $U,V,W$ be vector spaces, $S \in \L(V,W)$ and $T_1, T_2 \in \L(U,V)$, then for all $x \in V$ and by linearity of $S$, we have
        \begin{align*}
            [S(T_1 + T_2)](x) &= S((T_1 + T_2)(x)) \\
            &= S(T_1(x) + T_2(x)) \\
            &= S(T_1(x)) + S(T_2(x)) \\
            &= (S T_1)(x) + (S T_2)(x) \\
            &= [ST_1 + ST_2](x).
        \end{align*}
        Since it holds for all $x \in U$, then $S(T_1 + T_2) = ST_1 + ST_2$.\\
    \end{itemize}
\end{solution}

\begin{exercise}
    Show that every linear map from a one-dimensional vector space to itself is multiplicative by some scalar. More precisely, prove that if $\dim V = 1$ and $T \in \L(V)$, then there exists $\lambda \in \F$ such that $Tv = \lambda v$ for all $v \in V$. \\
\end{exercise}

\begin{solution}
    \\ Since $\dim V = 1$, then there is a $v_0 \in V$ such that $V = \text{span}(v_0)$. We have $Tv_0 \in \text{span}(v_0)$ so there is a $\lambda \in \F$ satisfying $Tv_0 = \lambda v_0$. Take $v \in V$, since $v \in \text{span}(v_0)$, then there is an $\alpha \in \F$ such that $v = \alpha v_0$. Thus:
    $$Tv = T\alpha v_0 = \alpha Tv_0 = \alpha \lambda v_0 = \lambda v.$$
\end{solution}

\begin{exercise}
    Give an example of a function $\varphi : \R^2 \to \R$ such that
    $$\varphi(av) = a\varphi(v)$$
    for all $a \in \R$ and all $v \in \R^2$ but $\varphi$ is not linear.\\
\end{exercise}

\begin{solution}
    \\ Consider the function $\varphi : \R^2 \to \R$ defined by $\varphi(x,y) = \sqrt[3]{(x + y)^3}$, then for all $x,y \in \R$ and $a \in \R$, we have
    \begin{align*}
        \varphi(ax, ay) &= \sqrt[3]{(ax + ay)^3} \\
        &= \sqrt[3]{a^3(x + y)^3} \\
        &= a\sqrt[3]{(x + y)^3} \\
        &= a \varphi(x,y).
    \end{align*}
    However, notice that $\varphi(1, 0) = \varphi(0,1) = 1$ but $\varphi(1, 1) = \sqrt[3]{2}$ so $\varphi(1, 1) \neq \varphi(1, 0) + \varphi(0,1)$ so $\varphi$ is not linear. \\
\end{solution}

\begin{exercise}
    Give an example of a function $\varphi : \C \to \C$ such that
    $$\varphi(w + z) = \varphi(w) + \varphi(z)$$
    for all $w,z \in \C$ but $\varphi$ is not linear. (Here, $\C$ is thought of as a complex vector space.)\\
\end{exercise}

\begin{solution}
    \\ Consider the function $\varphi : \C \to \C$ defined by $\varphi(z) = \Re(z)$, then for all $w,z \in \C$, we know that
    $$\Re(w + z) = \Re(w) + \Re(z).$$
    However, $\Re(i) = 0$ and $i \Re(1) = i$ so $\Re(i \cdot 1) \neq i\Re(1)$. Therefore, $\varphi$ is not linear. \\
\end{solution}

\begin{exercise}
    Prove or give a counterexample: If $q \in \P(\R)$ and $T: \P(\R) \to \P(\R)$ is defined by $Tp = q \circ p$, then $T$ is a linear map. \\
\end{exercise}

\begin{solution}
    \\ Consider the following counterexample: Take $q = x^2$ and define the map $T : \P(\R) \to \P(\R)$ by 
    $$Tp = q \circ p = p^2$$
    for all $p \in \P(\R)$. Notice that $T(x + 1) = x^2 + 2x + 1$ but $T(x) + T(1) = x^2 + 1$. Thus, $T(x + 1) \neq T(x) + T(1)$ so $T$ is not a linear map. \\
\end{solution}

\begin{exercise}
    Suppose $V$ is a finite-dimensional vector space and $T \in \L(V)$. Prove that $T$ is a scalar multiple of the identity if and only if $ST = TS$ for all $S \in \L(V)$. \\
\end{exercise}

\begin{solution}
    \\ First, let $T$ be a scalar multiple of the identity, then there is a $\lambda \in \F$ such that $Tv = \lambda v$ for all $v \in V$. Let $S$ be an arbitrary linear map from $V$ to $V$, then for all $v \in V$:
    $$(ST)v = S(Tv) = S(\lambda v) = \lambda Sv = T(Sv) = (TS)v.$$
    Since it holds for all $v \in V$, then $ST = TS$. \\
    To prove that the converse holds, fix a basis $v_1, ..., v_n$ of $V$ and for all $i$ between 1 and $n$, define $S_i$ as the linear map satisfying $S_iv_1 = v_i$ and $S_i v_k = 0$ for all $k \neq 1$ (such a linear map is well-defined and unique by Lemma 3.4). Let $T \in \L(V)$, then for all $i$ between 1 and $n$, there exist scalars $A_{i,1}, ..., A_{i,n} \in \F$ such that
    $$Tv_i = A_{i,1}v_1 + ... + A_{i,n}v_n. $$
    Suppose that $T$ satisfies $ST = TS$ for all $S \in \L(V)$, then in particular, for all fixed $i$ between 1 and $n$, we have $(S_i T)v_1 = (T S_i)v_1$. Using the definitions and properties of $S_i$ and $T$, we get that
    \begin{align*}
        (S_i T)v_1 = (T S_i)v_1 &\implies S_i(A_{1,1}v_1 + ... + A_{1,n}v_n) = T v_i \\
        &\implies A_{1,1}v_i = A_{i,1}v_1 + ... + A_{i,n}v_n
    \end{align*}
    and by uniqueness of representations of vectors in $V$ as linear combinations of the basis, we get that $A_{i,j} = 0$ for all $i \neq j$ and $A_{1,1} = A_{i,i}$. Thus, if we let $\lambda = A_{1,1}$, we obtain that for all $i$,
    $$Tv_i = A_{i,1}v_1 + ... + A_{i,n}v_n = \lambda v_i.$$
    Therefore, it follows that $T$ is equal to $\lambda$ times the identity map, i.e., a scalar multiple of the identity. \\
\end{solution}

\begin{exercise}
    Suppose $U$ is a subspace of $V$ with $U \neq V$. Suppose $S \in \L(U,W)$ and $S \neq 0$ (which means that $Su \neq 0$ for some $u \in U$). Define $T : V \to W$ by
    $$Tv = \begin{cases} Sv & \text{if } v \in U, \\ 0 & \text{if } v \in V \text{ and } v \notin U. \end{cases}$$
    Prove that $T$ is not a linear map on $V$. \\
\end{exercise}

\begin{solution}
    \\ Since $U \neq V$, then there is a $v_0 \in V \setminus U$. The fact that $S$ is not the zero transformation implies that there is a vector $u \in U$ such that $Su \neq 0$. Moreover, since $U$ is a subspace and $u \in U$, then $v_0 + u \in U$ implies that $v_0 \in U$. A contradiction that shows that $u + v_0 \in V \setminus U$. Thus, by definition of $T$, we have $Tv_0 = 0$ and $T(v_0 + u) = 0$. If $T$ is linear, then we would get
    $$0 = T(v_0 + u) = Tv_0 + Tu = Su.$$
    But this is a contradiction since we defined $u$ such that $Su \neq 0$. Thus, no such linear transformation $T$ exists. \\
\end{solution}

\begin{exercise}
    Suppose $V$ is finite-dimensional. Prove that every linear map on a subspace of $V$ can be extended to a linear map on $V$. In other words, show that if $U$ is a subspace of $V$ and $S \in \L(U,W)$, then there exists $T \in \L(V,W)$ such that $Tu = Su$ for all $u \in U$. \\
\end{exercise}

\begin{solution}
    \\ Let $u_1, ..., u_n$ be a basis of $U$, then it can be extended to a basis $u_1, ..., u_m$ of $V$ where $m \geq n$. Define $T$ on this basis as follows: $Tu_i = Su_i$ if $i \leq n$ and $Tu_i = 0$ otherwise. By Lemma 3.4, $T$ is a well-defined linear map from $V$ to $W$. Let's now prove that $T$ extends $S$. Let $u \in U$, then there exist scalars $\alpha_1, ..., \alpha_n \in \F$ such that 
    $$u = \alpha_1 u_1 + ... + \alpha_n u_n.$$
    Applying $T$ on both sides an using the linearity of $T$, we get
    $$Tu = \alpha_1 Tu_1 + ... + \alpha_n Tu_n.$$
    By construction of $T$, we know that $Tu_i = Su_i$ for all $i$ between 1 and $n$:
    $$Tu = \alpha_1 Su_1 + ... + \alpha_n Su_n.$$
    Finally, by linearity of $S$:
    $$Tu = S(\alpha_1 u_1 + ... + \alpha_n u_n) = Su.$$
    It follows that $T$ is linear map that extends $S$ on $V$. \\
\end{solution}

\begin{exercise}
    Suppose $V$ is finite-dimensional with $\dim V > 0$, and suppose $W$ is infinite-dimensional. Prove that $\L(V,W)$ is infinite-dimensional. \\
\end{exercise}

\begin{solution}
    \\ Let $v_1, ..., v_n$ be a basis of $V$. From Section 2A Exercise 17, we know that there exists a sequence $w_1, w_2, ...$ in $W$ such that the list $w_1, ..., w_m$ is linearly independent for all $m$. For all $k$, define the map $T_k : V \to W$ to be the unique linear map such that $T_k v_1 = w_k$ and $T_k v_i = 0$ for all $i$ between 2 and $n$. Let's show that for all $m$, the list $T_1, ..., T_m$ is linearly independent in $\L(V,W)$. Let $\alpha_1, ..., \alpha_n \in \F$ be scalars such that $$\alpha_1 T_1 + ... + \alpha_m T_m = 0,$$
    then in particular, if we plug-in $v_1$, we get
    $$\alpha_1 w_1 + ... + \alpha_m w_m = 0.$$
    By our assumption on the sequence $w_1, w_2, ...$, we know that it implies that $\alpha_1 = ... = \alpha_m = 0$. Thus, the list $T_1, ..., T_m$ is linearly independent. Since it holds for all $m$, then by Section 2A Exercise 17, $\L(V,W)$ is infinite-dimensional. \\
\end{solution}

\begin{exercise}
    Suppose $v_1, ..., v_m$ is a linearly dependent list of vectors in $V$. Suppose also that $W \neq \{0\}$. Prove that there exist $w_1, ..., w_m \in W$ such that no $T \in \L(V,W)$ satisfies $Tv_k = w_k$ for each $k = 1, ..., m$. \\
\end{exercise}

\begin{solution}
    \\ If the list has length 1, then $v_1$ must be zero vector so it suffices to take $w_1 \in W\setminus \{0\}$. Hence, every linear map $T$ would map $v_1$ to zero which is different than $w_1$. \\
    Assume that $m > 1$, since the list $v_1, ..., v_m$ is linearly independent, then without loss of generality, we can assume that $v_m$ can be written as a linear combination of the other vectors. Thus, let $w_1 = ... = w_{m-1} = 0$ and $w_m \in W \setminus \{0\}$ (which must exists since $W \neq \{0\}$). Let $T$ be a linear map and suppose that $T v_k = w_k$ for each $k = 1, ..., m$. However, since there exist scalars $\alpha_1, ..., \alpha_{m-1}$ such that
    $$v_m = \alpha_1 v_1 + ... + \alpha_{m-1}v_{m-1},$$
    then by applying $T$ on both sides, we get
    $$Tv_m = \alpha_1 Tv_1 + ... + \alpha_{m-1}Tv_{m-1} = 0 \neq w_m.$$
    Therefore, no linear map $T$ satisfies $T v_k = w_k$ for each $k = 1, ..., m$.\\
\end{solution}

\begin{exercise}
    Suppose $V$ is finite-dimensional with $\dim V > 1$. Prove that there exist $S,T \in \L(V)$ such that $ST \neq TS$. \\
\end{exercise}

\begin{solution}
    \\ We know from Exercise 11 that the linear maps that commute with every other linear map are precisely the scalar multiples of the identity map. Hence, it suffices to show that there exists a linear map that is not a scalar multiple of the identity. Let $v_1, ..., v_n$ be a basis of $V$ (so $n \geq 2$) and define $T : V \to V$ to be the unique linear map such that $Tu_1 = u_1$ and $Tu_i = 0$ for $i$ between 2 and $n$. Such a transformation exists by Lemma 3.4. If $T$ was a scalar multiple of the identity, then $Tu_1 = u_1$ would imply that $T$ is the identity since $u_1$. However, $Tu_2 = 0$ even if $u_2 \neq 0$. Thus, by contradiction, $T$ is not a scalar multiple of the identity. Therefore, there must be a linear map $S$ such that $ST \neq TS$.\\
\end{solution}

\begin{exercise}
    Suppose $V$ is finite-dimensional. Show that the only two-sided ideals of $\L(V)$ are $\{0\}$ and $\L(V)$. \\
\end{exercise}

\begin{solution}
    \\ Let $\mathcal{E}$ be a two-sided ideal of $\L(V)$, if $\mathcal{E} = \{0\}$, then we are done. Assume that $\mathcal{E} \neq \{0\}$, then there must be a non-zero linear map $T$ in $\mathcal{E}$ and scalars $\{A_{i,j}\} \subset \F$ such that 
    $$T v_j = A_{1,j}v_1 + ... + A_{n,j}v_n$$
    for all $j$ between 1 and $n$. Since $T$ is non-zero, then it follows that there exist $i_0$ and $j_0$ between 1 and $n$ such that $A_{i_0, j_0} \neq 0$. Moreover, for all $i$ and $j$ between 1 and $n$, define the linear map $S_{i,j} \in \L(V)$ by
    $$S_{i,j} v_k = \begin{cases} v_i & k = j, \\ 0 & k \neq j. \end{cases}$$
    Consider the map $\frac{1}{A_{i_0,j_0}}S_{i_0,i_0}T S_{j_0, j_0}$, since $\mathcal{E}$ is a two-sided ideal, then this map belongs to $\mathcal{E}$. Let $k$ be an integer between 1 and $n$, if $k \neq j_0$, then
    $$\frac{1}{A_{i_0,j_0}}S_{i_0,i_0}T S_{j_0, j_0} v_k = \frac{1}{A_{i_0,j_0}}S_{i_0,i_0}T(0) = 0,$$ 
    and if $k = j_0$, then 
    \begin{align*}
        \frac{1}{A_{i_0,j_0}}S_{i_0,i_0}T S_{j_0, j_0} v_k &= \frac{1}{A_{i_0,j_0}}S_{i_0,i_0}Tv_{j_0} \\
        &= \frac{1}{A_{i_0,j_0}}S_{i_0,i_0}(A_{1,j_0}v_1 + ... + A_{n,j_0}v_n)\\
        &= \frac{1}{A_{i_0,j_0}}A_{i_0, j_0}v_{i_0}\\
        &= v_{i_0}.
    \end{align*}
    Thus, by definition of the maps $S_{i,j}$'s and by uniqueness part of Lemma 3.4, we get that
    $$\frac{1}{A_{i_0,j_0}}S_{i_0,i_0}T S_{j_0, j_0} = S_{i_0, j_0}.$$
    Hence, the map $S_{i_0, j_0}$ is in $\mathcal{E}$. From this, we get that for all $i$ and $j$ between 1 and $n$, the map $S_{i,i_0}S_{i_0, j_0} S_{j_0, j}$ is in $\mathcal{E}$ as well. But notice that for all $k$ between 1 and $n$, if $k \neq j$, then
    $$S_{i,i_0}S_{i_0, j_0} S_{j_0, j} v_k = 0,$$
    and $k = j$, then 
    $$S_{i,i_0}S_{i_0, j_0} S_{j_0, j} v_k = S_{i,i_0}S_{i_0, j_0} v_{j_0} = S_{i,i_0}v_{i_0} = v_i.$$
    Thus, again, by the uniqueness part of Lemma 3.4 and since it holds for all $i,j$, then $S_{i,j} \in \mathcal{E}$ for all $i,j$. We are now ready to show that $\mathcal{E} = \L(V)$. Since $\mathcal{E}$ is a subspace of $\L(V)$, then it suffices to prove that $\L(V) \subset \mathcal{E}$. Let $S \in \L(V)$, then there exist scalars $\{B_{i,j}\}_{i,j} \subset \F$ such that
    $$S v_j = B_{1,j}v_1 + ... + B_{n,j}v_n,$$
    for all $j$. Consider the map $\tilde{S}$ defined by
    $$\tilde{S} = \sum_{i=1}^{n}\sum_{k=1}^{n}B_{i,k}S_{i,k}.$$
    Since $\mathcal{E}$ is a subspace that contains all the $S_{i,j}$'s, then $\tilde{S} \in \mathcal{E}$. Moreover, notice that for all $j$,
    $$\tilde{S}v_j = \sum_{i=1}^{n}\sum_{k=1}^{n}B_{i,k}S_{i,k} v_j = \sum_{i=1}^{n}B_{i,j}v_i = Sv_j.$$
    Since it holds for all $j$, then by Lemma 3.4, we have that $S = \tilde{S} \in \mathcal{E}$. Since it holds for all $S \in \L(V)$, then $\L(V) = \mathcal{E}$. Therefore, the only two-sided ideals of $\L(V)$ are $\{0\}$ and $\L(V)$.  \\
\end{solution}
