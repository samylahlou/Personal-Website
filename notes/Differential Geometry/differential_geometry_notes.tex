\documentclass{article}

%% Language and font encodings
\usepackage[english]{babel}
\usepackage[utf8x]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{amsfonts}
\usepackage[margin=41mm]{geometry}

%% Sets page size and margins
%\usepackage[a4paper,top=3cm,bottom=2cm,left=3cm,right=3cm,marginparwidth=1.75cm]{geometry}

%% Useful packages
\usepackage[colorlinks=true, allcolors=black]{hyperref}
\usepackage{amsmath}
\usepackage{xcolor}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{stmaryrd}
\usepackage{graphicx}
\usepackage{enumitem}
\usepackage{tikz, pgfplots}
\usetikzlibrary{positioning}

%Theorem
\theoremstyle{definition}
\newtheorem{theorem}{Theorem}[subsection]
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem*{corollary}{Corollary}
\theoremstyle{definition}
\newtheorem*{definition}{Definition}

%Usual Sets
\newcommand{\C}{\mathbb{C}}
\newcommand{\R}{\mathbb{R}}
\newcommand{\Q}{\mathbb{Q}}
\newcommand{\Z}{\mathbb{Z}}
\newcommand{\N}{\mathbb{N}}
\newcommand{\F}{\mathbb{F}}
\newcommand{\E}{\mathbb{E}}
\newcommand{\K}{\mathbb{K}}
\newcommand{\D}{\mathbb{D}}
\newcommand{\Zn}[1]{\mathbb{Z}/ #1 \mathbb{Z}}
\renewcommand{\P}{\mathcal{P}}

%Special Sets
\newcommand{\Iint}[2]{\llbracket #1 , #2 \rrbracket}

%Math Operators
\let\Re\relax
\let\Im\relax
\DeclareMathOperator{\Im}{Im}
\DeclareMathOperator{\Re}{Re}
\DeclareMathOperator{\Null}{null}
\DeclareMathOperator{\range}{range}
\DeclareMathOperator{\card}{card}
\DeclareMathOperator{\Vol}{Vol}
\DeclareMathOperator{\curl}{curl}
\DeclareMathOperator{\dotp}{\boldsymbol{\cdot}}

%Others
\newcommand{\td}{\textcolor{red}{\textbf{TODO}}}
\newcommand{\isomorphic}{\cong}
\newcommand{\lnorm}[2]{\left\lVert#2 \right\rVert_{#1}}
\newcommand{\norm}[1]{\left\lVert#1 \right\rVert}

%Example environment
\newenvironment{example}{\noindent\textbf{Example:} \vspace{-0.2cm}\begin{itemize}}{\end{itemize}}

%Set QED symbol to blacksquare
\renewcommand\qedsymbol{$\blacksquare$}

%Enumerate Default Symbol
\setlist[enumerate,1]{label={(\alph*)}}


\title{MATH 458 Notes : Honours Differential Geometry}
\author{Samy Lahlou}
\date{}

\begin{document}

\maketitle

\pagenumbering{gobble}

These notes are based on lectures given by Professor Jean Pierre Mutanguha at McGill University during the Winter 2026 semester. These lectures will introduce the local \& global theory of curves and surfaces in two and three dimensions. As a disclaimer, it is more than possible that I made some mistakes. Feel free to correct me or ask me anything about the content of this document at the following address : samy.lahloukamal@mcgill.ca

\tableofcontents

\newpage

\pagenumbering{arabic}

\section{Preliminaries}

\subsection{Linear Algebra}

In this course, we will focus on the vector space
$$\R^n = \{(x_1, ..., x_n) \ : \ x_i \in \R\},$$
especially $\R^2$ and $\R^3$ even if everything that will be covered can be generalized for $\R^n$ where $n \geq 2$ is arbitrary. We will also care about the standard dot product on $\R^n$, defined by
$$\textbf{v} \dotp \textbf{w} = \sum_{i}v_iw_i.$$
This is an example of an \textit{inner product}, i.e., a symmetric function $\langle \dotp , \dotp \rangle : \R^n \times \R^n \to \R$, bilinear, and positive definite. Notice that for any invertible linear transformation $T$ from $\R^n$ to $\R^n$, we can define a new inner product $b_T : (v,w) \mapsto Tv \dotp Tw$. It turns out that every inner product on $\R^n$ is of this form for some linear transformation $T$. Using the inner product, we can define the usual notions of Euclidean norm and Euclidean distance in the vector space $\R^n$:
$$\norm{v} = \sqrt{v \dotp v}$$
and 
$$d(v,w) = \norm{v-w}.$$

The goal now is to define what it means for a transformation to be a rigid motion. Intuitively, a rigid motion is like a translation or a rotation, it preserves distances. This motivates the following definition.

\begin{definition}
    A linear transformation $T : \R^n \to \R^n$ is \textit{orthogonal} if the following conditions are satisfied:
    \begin{itemize}
        \item $T(v) \dotp T(w) = v \dotp w$ for all $v,w \in \R^n$,
        \item $\norm{T(v)} = \norm{v}$ for all $v \in \R^n$,
        \item $d(T(v), T(w)) = d(v,w)$ for all $v ,w \in \R^n$.
    \end{itemize}
\end{definition}

It turns out that the three conditions in this definition are equivalent. This should not be surprising since the notions of norm and distance are both defined in terms of the dot product. Let's prove this.

\begin{proposition}
    The following are equivalent:
    \begin{enumerate}[label=(\arabic*)]
        \item $T(v) \dotp T(w) = v \dotp w$ for all $v,w \in \R^n$,
        \item $\norm{T(v)} = \norm{v}$ for all $v \in \R^n$,
        \item $d(T(v), T(w)) = d(v,w)$ for all $v ,w \in \R^n$.
    \end{enumerate}
\end{proposition}

\begin{proof}
    Condition (1) implies condition (2) because if $T$ preserves the dot product, then $T(v)\dotp T(v) = v\dotp v$ for all $v \in V$. Taking the square root on both sides gives us precisely condition (2). Condition (2) implies condition (3) because replacing $v$ with $v - w$ in condition (2) gives us $\norm{T(v - w)} = \norm{v - w}$ which is equivalent to $d(T(v),T(w)) = d(v,w)$. Similarly, condition (3) implies condition (2) by taking $w = 0$.
    
    Finally, we need to show that conditions (2) and (3) imply condition (1). To do so, let $v,w \in V$, then $d(T(v), T(w)) = d(v,w)$. Squaring both sides and using the definition of the distance gives us
    $$(v-w)\dotp (v-w) = (T(v) - T(w)) \dotp (T(v) - T(w)).$$
    By symmetry and bilinearity of the dot product, we can expand both sides to get
    $$v\dotp v - 2(v\dotp w) + w\dotp w = T(v)\dotp T(v) - 2(T(v)\dotp T(w)) + T(w)\dotp T(w).$$
    By condition (2), $v\dotp v = T(v)\dotp T(v)$ and $w\dotp w = T(w)\dotp T(w)$, hence, after cancelling the terms:
    $$v\dotp w = T(v)\dotp T(w)$$
    which is exactly condition (1).
\end{proof}

For the moment, an orthogonal transformation is not exactly what we have in mind when we talk about rigid motions. For example, the transformation $T: \R^2 \to \R^2$ defined by  $T(x,y) = (-x, y)$ is an orthogonal transformation, but it flips the plane so it is not a rigid motion. The following proposition makes the phenomenon more precise.

\begin{proposition}
    If $T$ is an orthogonal transformation, then $\det(T) = \pm 1$.
\end{proposition}

\begin{proof}
    Let $e_1, ..., e_n$ be the standard basis in $\R^n$. Let $A = (a_{ij})_{ij}$ be the matrix representation of the orthogonal transformation $T$, then $Te_i = \sum_k a_{ik}e_k$. Since $T$ is orthogonal, then it preserves the inner product. It follows that $Te_i \dotp Te_j = \delta_{ij}$. But on the other hand, we have that $Te_i \dotp Te_j = \sum_k a_{ik}a_{jk}$. Next, consider the matrix $AA^T$, its coefficient with index $ij$ is equal to $\sum_k a_{ik}b_{kj}$ where $A^T = (b_{ij})_{ij}$. But since $b_{ij} = a_{ji}$ holds for all $i$ and $j$, then the coefficient with index $ij$ in $AA^T$ is
    $$\sum_k a_{ik}a_{jk} = Te_i \dotp Te_j = \delta_{ij}.$$
    In other words, $AA^T = I_n$. Taking the determinant on both sides gives us $\det(AA^T) = 1$. Since the determinant preserves the product of matrices, and $\det(A^T) = \det(A)$, then the last equation is equivalent to $\det(A)^2 = 1$. Therefore, $\det(T)= \det(A) = \pm 1$.
\end{proof}

We can think of a transformation with negative determinant in $R^2$ as a transformation that flips the plane. More generally, such a transformation can be thought as changing the orientation of the space. This motivates the next definition.

\begin{definition}
    A linear transformation $T$ is \textit{orientation-preserving} if $\det (T) > 0$.
\end{definition}

An orthogonal orientation-preserving transformation can be thought as rotations about the origin. Hence, if we combine the last two definitions, it would be tempting to say that we would get the definition of a rigid motion. However, our definitions only apply to linear transformations, and not translations for example. This is precisely what is the left to add in our definition of a rigid motion.

\begin{definition}
    A function $M : \R^n \to \R^n$ is a \textit{rigid motion} if there is an element $a \in \R^n$ and an orthogonal orientation-preserving transformation $T : \R^n \to \R^n$ such that $M(v) = T(v) + a$ for all $v \in \R^n$. Equivalently, a rigid motion is an affine linear map where linear part is orthogonal and orientation-preserving.
\end{definition}

The notion of rigid motion is really important in this course because it lets us focus on the important properties of curves and surfaces. For example, the curvature of a curve at a point is invariant under rigid motions. This shows that the curvature is a property that doesn't depend on where the curve is exactly in the space. More generally, the properties we are going to study are these properties that are invariant under rigid motions. To avoid saying that a property is invariant up to rigid motions many times, we will replace sentences like 
\begin{align*}
    \text{"T}& \text{he length of a regular curve }\mathcal{C} \subset \R^n \text{ is defined in terms of the length of its }\\ &\text{ parametrization. The length of a curve is invariant up to rigid motions."}
\end{align*}
with
\begin{align*}
    \text{"The length of a regular curve }\mathcal{C} \subset \E^n \text{ is defined  }\\ \text{in terms of the length of its parametrization."}
\end{align*}
In short, $\R^n$ is replaced with $\E^n$ whenever the stated property is invariant under rigid motions.

\subsection{Topology}

In the previous section, we defined the notion of rigid motion, in this section, we define the basic notions of topology required for this course. The most basic notion of topology is the notion of an open set. An open set can be seen as a generalization of an open interval in $\R$. To make this precise, let's first define what disks are in $\R^n$. 

\begin{definition}
    Given $\epsilon > 0$ and $p \in \R^n$, we define the \textit{open disk} (or simply \textit{disk}) as
    $$\D_{\epsilon}(p) = \{q \in \R^n \ : \ d_{\E}(p,q) < r\}.$$
    We also define the closed \textit{closed disk} as
    $$\overline{\D_{\epsilon}(p)} = \{q \in \R^n \ : \ d_{\E}(p,q) \leq r\}.$$
\end{definition}

Even if open and closed disks seem very similar by looking at their definitions, they are in fact very different. To see this difference, suppose that a certain property holds precisely for the points in the open disk $\D_{\epsilon}(0)$, then we can say that whenever a point $p$ satisfies this property, then there is a small open disk around $p$ such that every point in this smaller disk satisfies this property. However, this is not the case for the closed disk because if we take a point on the boundary, any disk around that point will have elements inside and outside the closed disk. From this, we can now define the what it means for a general set to be open.

\begin{definition}
    A set $U \subset \R^n$ is \textit{open} if for all $p \in U$, there is a $\epsilon > 0$ such that $\D_{\epsilon}(p) \subset U$. A set $A \subset \R^n$ is \textit{closed} if its complement is open.
\end{definition}

The open sets really capture the notion of interior. Every point is at the interior of the set, no point is alone, or on the boundary. The open sets satisfy the following properties.
\begin{proposition}
    \begin{enumerate}
        \item Let $\{U_i\}_i$ be an arbitrary collection of open subsets of $\R^n$, then $\bigcup_iU_i$ is an open set.
        \item Let $\{U_1, ..., U_n\}$ be a finite collection of open subsets of $\R^n$, then $\bigcap_{i=1}^n U_i$ is an open set.
    \end{enumerate}
\end{proposition}

The notion of disk is also useful to talk about boundedness. In $\R$, a set is bounded if every point satsfies $|x| < M$ for some uniform upper bound $M$. Equivalently, a set is bounded if it is contained in the interval $(-M, M) = \D_M(0)$. This motivates the following more general definition.

\begin{definition}
    A set is \textit{bounded} if it is contained in a disk (open or closed).
\end{definition}

We see that topology is giving us tools to characterize sets. We defined the notion of open, closed, and bounded sets. There is one last type of sets which will be important for this course that we need to define. 

\begin{definition}
    A set $C \subseteq \R^n$ is \textit{compact} if whenever there is a collection of open sets $\{U_i\}_i$ such that $C \subseteq \bigcup_i U_i$, then there is a subcollection $\{U_1, ..., U_n\}$ such that $C \subseteq \bigcup_{i=1}^n U_i$.
\end{definition}

The notion of compactness may seem very obscure and useless, but it turns out that compact sets are, in a sense, a generalization of finite sets. Morever, compact sets are very nice to work with for their numerous properties. Thankfully, the following theorem will give us a very useful equivalent definition for compact sets in $\R^n$. 

\begin{theorem}[Heine-Borel]
    A subset $C \subset \R^n$ is compact if and only if it is closed and bounded.
\end{theorem}

As always in mathematics, after adding more structure to a set, we need to define what it means for a function interact well with that new structure. In particular, we need to define what it means for a function from $\R^n$ to $\R^m$ to preserve open sets. This motivates the following definition.

\begin{definition}
    A function $f : \R^n \to \R^m$ is \textit{continuous} if $f^{-1}(U) \subseteq \R^n$ is open for all open subsets $U \subseteq \R^m$. If $f$ is continuous, bijective, and its inverse is also continuous, then $f$ is a \textit{homeomorphism}.
\end{definition}

Here are important properties of continuous functions:

\begin{proposition}
    Let $f : \R^n \to \R^m$ be a continuous function.
    \begin{enumerate}
        \item $f^{-1}(A) \subseteq \R^n$ is closed for all closed sets $A \subseteq \R^m$.
        \item If $C \subseteq \R^n$, then $f(C) \subseteq \R^m$ is compact.
    \end{enumerate}
\end{proposition}

We will not need more topology than what is contained in this section.

\subsection{Vector Calculus}

In this section, we will state the most important theorem from Vector Calculus: the Inverse Function Theorem. But first, let's define the notion of differentiability at a point.

\begin{definition}
    Given a function $f : U \subset \R^n \to \R^m$ and a point $a \in U$ where $U$ is open, then $f$ is differentiable at $p$ if there is a linear transformation $D_pf : \R^n \to \R^m$ called the \textit{Jacobian} such that
    $$\lim_{x \rightarrow p}\frac{\norm{f(x) - f(p) - D_pf(x - p)}}{\norm{x - p}} = 0.$$
    The Jacobian of $f$ at $p$ can be seen as the derivative of $f$ at $p$.
\end{definition}

\td

The Jacobian satisfies the following usual properties.

\begin{proposition}
    If a function $f$ is differentiable at $p$, then $f$ is continuous at $p$.
\end{proposition}

\begin{proposition}
    If $f, g : U \subseteq \R^n \to \R^m$ are two functions differentiable at $p \in U$, then
    \begin{enumerate}
        \item for all $\lambda \in \R$, $\lambda f$ is differentiable at $p$ and $D$
    \end{enumerate}
\end{proposition}

In a first multivariable calculus class, we generalize the notion of a derivative by introducing the notion of partial derivatives of a function. The following theorem shows that Partial Derivatives and Jacobians are related:

\begin{proposition}
    Let $f = (f_1, ..., f_m) : U \subseteq \R^n \to \R^m$ be a function, and $p$ be a point in the open set $U$.
\end{proposition}

Most of the usual properties of derivatives also hold for the Jacobian.

\begin{proposition}
    Let $f$ and $g$ be two functions differentiable at a point $a$.
    \begin{enumerate}
        \item 
    \end{enumerate}
\end{proposition}

\begin{proposition}
    If $f$ is differentiable at $a$, then the entries in the Jacobian are the partial derivatives of $f$ at $a$: \td.
\end{proposition}

We can define C1, Cn, smooth ... partial derivatives.

diff at a implies continuous at a. \td 

\begin{theorem}
    \begin{enumerate}
        \item $C^1 \implies$ differentiable ($\implies C^0$)
        \item $C^{k+1} \implies C^k$.
    \end{enumerate}
\end{theorem}

\section{Curves}

\subsection{Definitions}

We are going to define the notion of curve. We are going to focus on properties of curves which are invariant under rigid motions.

\begin{definition}
    A \textit{parametrized curve} (\textit{path}) in $\E^n$ is a continuous function $\gamma : I \to \E^n$, where $I \subset \R^1$ is an interval (closed or open, bounded or unbounded).
\end{definition}

\begin{proposition}
    Given a curve $\gamma : I \to \R^n$, if $I$ is compact, then the image of $\gamma$ is compact. In that case, we say that the path is compact.
\end{proposition}

\begin{proof}
    \td 
\end{proof}

\begin{definition}
    A parametrized curve $\gamma : I \to \R^n$ is regular if $\gamma'(t) \neq 0$ for all $t \in I$.
\end{definition}

\begin{definition}
    A parametrized curve $\gamma : I \to \R^n$ is $C^k$ is $\gamma$ is $C^k$.
\end{definition}

We need to fix a coordinate system to talk about partial derivatives because we need to break the function into the coordinate components. However, we can prove that if a function is $C^k$ for a coordinate system, then it is $C^k$ for any coordinate system.

\begin{proposition}
    If $\gamma : I \to \R^n$ is a (regular) $C^k$ parametrized curve and $M : \R^n \to \R^n$ is a rigid motion, then $\tilde{\gamma} = M\circ \gamma: I \to \R^n$ is a (regular) $C^k$ parametrized curve in $\R^n$.
\end{proposition}

\begin{proof}
    \td
\end{proof}

\begin{definition}
    The velocity of $\gamma$ is $\nu : \gamma' : I \to \R^n$, then speed is $\norm{\nu} : I \to \R$, and the acceleration is $\alpha = \gamma'' : I \to \R^n$.
\end{definition}

\begin{proposition}
    The speed of a path is preserved by rigid motions.
\end{proposition}

\begin{proof}
    \td 
\end{proof}

Consider the curve $\gamma : \R \to \R^2$ given by $\gamma(t) = (t, |t|)$, it is $C^0$ but not $C^1$. Similarly, the curve $\gamma(t) = (t^3, |t|^3)$ is not $C^2$ but not $C^3$, even though it has the same image as the previous curve (!). It turns out that we can also find an example with the same image which is $C^{\infty}$ this time.

\begin{definition}
    Let $\gamma : I \to \E^n$ be a $C^1$ parametrized curve where $I$ is a bounded integeral. The arclength of $\gamma$ is
    $$l(\gamma) = \int_I\norm{\nu(t)}dt.$$
\end{definition}

Let $p,q \in \E^2$ with $d_{\E}(p,q) = 3$, and $\gamma : [a,b] \to \E^2$ $C^1$ path with $\gamma(a) = p$ and $\gamma(b) = q$. Let's show that $l(\gamma) \geq 3$, and that equality holds if and only if $\gamma$ is a line segment with no change in direction. First, fix an origin at $p$ and an axis from $p$ to $q$ so that $\E^2 \isomorphic \R^2$, then we can write $\gamma = (x,y)$ where $x$ and $y$ are the coordinate functions. Hence:
$$l(\gamma) = \int_{a}^{b}\sqrt{\left(\frac{dx}{dt}\right)^2 + \left(\frac{dy}{dt}\right)^2} dt \geq \int_{a}^{b}\left|\frac{dx}{dt}\right|dt \geq \left|\int_{a}^{b}\frac{dx}{dt}\right|dt = |x(b) - x(a)| = 3.$$
If equality holds if and only if $dy/dt$ is always zero (the curve is a line) and $dx/dt$ is always positive (the curve never change direction).

\begin{definition}
    A subset $\mathcal{C} \subset \E^n$ is a ($C^k$) curve if is connected and for all points $p \in G$, there exists a compact neighborhood $N_p$ of $p$ and a one-to-one compact (regular $C^k$) parametrized curve $\gamma : I \to \E^n$ such that $\gamma(I) = \mathcal{C} \cap N_p$.
\end{definition}

From this definition, we say that the unit circle is a curve which is not the image of a single parametrized curve. The logarithmic spiral is a curve, even if we add the origin. \\

Some examples of curves. [desmos \td] \\

\subsection{Reparametrization}

\begin{definition}
    Given two paths $\gamma : I \to \R^n$ and $\tilde{\gamma} : \tilde{I} \to \R^n$, then $\tilde{\gamma}$ is a \textit{reparametrization} of $\gamma$ if there is a homeomorphism $t : \tilde{I} \to I$ such that $\tilde{\gamma} = \gamma \circ t$.
\end{definition}

The change of parameter $t$ is orientation preserving if it is increasing, otherwise, it is orientation-reversing.\\

Suppose $\gamma$ is a regular $C^k$ path and $t : \tilde{I} \to I$ is a $C^k$ bijection with $C^k$ inverse (which is equivalent to be a $C^k$ bijection with the derivative nonzero everywhere by the Inverse Function Theorem), then $\tilde{\gamma}$ is a $C^k$ reparametrization of $\gamma$. \\

We can reparametrize the logarithmic spiral so that the domain is finite (using the tangent reparametrization). We use this reparametrization to show that the logarithmic spiral with the additional zero point is a curve by making the finite domain of the reparametrization compact (by adding a point).

\begin{theorem}
    Given a connected subset $\mathcal{C} \subset \R^n$, then $\mathcal{C}$ is a regular $C^k$ curve if and only if $\mathcal{C}$ is the image of a regular $C^k$ path $\gamma: I \to \R^n$ satisfying one the following definition: $\gamma$ is injective with a continuous inverse that is $C^k$, or $I = \R$, $\gamma$ is periodic and the restriction of $\gamma$ to any compact interval shorter than the period is one-to-one.
\end{theorem}

Any regular $C^k$ path is called a global parametrization of the image curve.

\begin{theorem}
    Suppose $\gamma$ is $C^1$ and $\tilde{\gamma}$ is a $C^1$ reparametrization of $\gamma$, then $l(\gamma) = l(\tilde{\gamma})$.
\end{theorem}

\begin{proof}
    Use chain rule and the Fundamental Theorem of Calculus. \td
\end{proof}

\begin{definition}
    Arclength parametrization. $s(t) = \int_{t_0}^{t}\norm{\gamma dot (t)}dt$. By FTC, $s'(t) > 0$ on $I$, so $s$ is strictly increasing. Set $\tilde{I} = s(I)$, then $s : I \to \tilde{I}$ is an orientation-preserving $C^1$ bijection with $s' > 0$. By the Inverse Function Theorem, $t = s^{-1} : \tilde{I} \to I$ is an orientation preserving $C^1$ bijection and $t'(s) = 1/\norm{gamma dot (t(s))}$.
\end{definition}

[\td change notation for speed and velocity by replacing $\nu$ with gamma dot. \td] \\

What is the length of a curve ?

exercise: the last two definitions of length agree.\\

Let $\gamma$ be a path and $\tilde{\gamma}$ a reparametrization with constant speed $c$.
\begin{lemma}
    $\ddot{\tilde{\gamma}}\perp\dot{\tilde{\gamma}}$.
\end{lemma}

\begin{proof}
    First, notice that
    $$\dot{\tilde{\gamma}}\dotp\dot{\tilde{\gamma}} = \norm{\ddot{\tilde{\gamma}}}^2 = c.$$
    Hence, if we take the derivative, we get
    $$\frac{d}{dt}(\dot{\tilde{\gamma}}\dotp\dot{\tilde{\gamma}}) = 0.$$
    But notice that the product rule gives us
    $$\frac{d}{dt}(\dot{\tilde{\gamma}}\dotp\dot{\tilde{\gamma}}) = \ddot{\tilde{\gamma}}\dotp\dot{\tilde{\gamma}} + \dot{\tilde{\gamma}}\dotp\ddot{\tilde{\gamma}} = 2(\ddot{\tilde{\gamma}}\dotp\dot{\tilde{\gamma}})$$
    Thus, $\ddot{\tilde{\gamma}}\dotp\dot{\tilde{\gamma}} = 0$ which directly implies that $\ddot{\tilde{\gamma}}\perp\dot{\tilde{\gamma}}$.
\end{proof}

\subsection{Curvature}

Given a regular $C^2$ path $\gamma : I \to \R^n$, we can find an orientation-preserving change of parameters $t : \tilde{I} \to I$ and define $\tilde{\gamma} = \gamma \circ t : \tilde{I} \to \R^n$ such that $\tilde{\gamma}$ has unit speed. Let $s = t^{-1} : I \to \tilde{I}$.

\begin{definition}
    Define the \textit{curvature} of $\gamma$ at time $t$ to be $\kappa_{\gamma}(t) = \norm{\ddot{\tilde{\gamma}}(s(t))}$.
\end{definition}

In the homework, we prove that the curvature is well-defined.\\

Given a regular $C^2$ curve $\mathcal{C} \subset \R^n$, and a point $p \in \mathcal{C}$, the Classification Theorem implies that there is a global regular $C^2$ parameter $\gamma : I \to \R^n$ of $\mathcal{C}$. So there is some time $t \in I$ such that $\gamma(t) = p$. Define the curvature of $\mathcal{C}$ at $p$ to be the curvature of $\gamma$ at time $t$. \\

This is well-defined by the fact that every two global parametrization of a regular curve are related by a change of parameter, and hence, it follows from the well-definedness of the curvature for paths.\\

Exercise: Curvature is preserved by rigid-motions of $\R^n$, i.e., $\kappa_{\gamma} = \kappa_{M\circ \gamma}$ where $M$ is a rigid motion of $\R^n$. \\

\begin{proposition}
    $$\kappa_{\gamma} = \frac{1}{\norm{\dot{\gamma}}^2}\norm{\ddot{\gamma} - \left(\frac{\ddot{\gamma} \dotp \dot{\gamma}}{\dot{\gamma} \dotp \dot{\gamma}}\right)\dot{\gamma}} = \frac{\norm{\ddot{\gamma}^{\perp}}}{\norm{\dot{\gamma}}^2}$$
\end{proposition}

\begin{proof}
    \td
\end{proof}

\begin{definition}
    Let $\gamma : I \to \R^n$ be a regular path. Define the unit tangent vector as
    $$T(t) = \frac{\dot{\gamma}(t)}{\norm{\dot{\gamma}(t)}}.$$
\end{definition}

\begin{definition}
    Let $\gamma : I \to \R^n$ be a $C^2$ regular path with nonzero curvature. Define the unit normal vector as
    $$N(t) = \frac{\ddot{\gamma}(t)^{\perp}}{\norm{\ddot{\gamma}(t)^{\perp}}}.$$
\end{definition}

\begin{definition}
    The osculating plane at time $t$: contains $\gamma(t)$ and spanned by $\{\dot{\gamma}(t), \ddot{\gamma}(t)\}$ assuming the curvature is nonzero.
    
    The osculating circle at time $t$: circle in the osculating plane of radius $1/\kappa_{\gamma}(t)$, and center $\gamma(t) + N(t)/\kappa_{\gamma}(t)$. The path formed by the center of the osculating circles is called the evolute of $\gamma$.
\end{definition}

Exercise: The curvature of a circle of radius $r$ is $1/r$. \\


\noindent Jeudi 22 Janvier:
\begin{definition}
    Let $\gamma$ be a regular curve with tangent vector function $T(t)$, there is a unique function $\theta$ such that $T = \rho \circ \theta$ where $\rho(\theta) = (\cos\theta, \sin\theta)$. This function $\theta(t)$ is called the angle function.
\end{definition}

\subsection{Space paths}

Let's move to dimension 3. Let $\gamma : I \to \R^3$ be a regular $C^2$ path with positive curvature $\kappa > 0$. Since it has positive curvature, the tangent and normal vectors are always defined. Since we are working in $\R^3$, we can define a third vector to form a basis.

\begin{definition}
    We define the \textit{binormal} vector $B(t)$ as the tangent vector crossed with the normal vector, in other words, $B(t) = T(t) \times N(t)$. These three vectors form a basis which we call the \textit{Frenet Frame}.
\end{definition}

Now, we assume that the curve is $C^3$ and parametrized by arclength. Hence, $T = \dot\gamma$ and $\frac{dT}{ds} = \norm{\ddot{\gamma}} \cdot N = \kappa \cdot \kappa$. Since $\norm{B} \equiv 1$, then $\frac{dB}{ds} \dotp B \equiv 0$. Since $B = T \times N$, then
$$\frac{dB}{ds} = \frac{dT}{ds} \times N + T \times \frac{dN}{ds}.$$
But $\frac{dT}{ds} = \kappa \cdot \kappa$ so $\frac{dT}{ds} \times N = \kappa \cdot N \times N = 0$. Hence, 
$$\frac{dB}{ds} =T \times \frac{dN}{ds}.$$
It follows that $\frac{dB}{ds} \cdot T \equiv 0$. Since $dB/ds$ is perpendicular to $B$ and $T$, then it must be parallel to $N$. We define the torsion of $\gamma$, $\tau(s)$ as the constant such that 
$$\frac{dB}{ds}(s) = -\tau(s)N(s),$$
or in other words, 
$$\tau(s) = - \frac{dB}{ds}(s) \cdot N(s).$$
Since $\norm{N} = 1$, then $\frac{dN}{ds}\dotp N \equiv 0$. Since $T \dotp N \equiv 0$, then $T \dotp \frac{dN}{ds} = - \kappa$, and similrly, $B \dotp \frac{dN}{ds} = \tau$. Hence,
$$\frac{dN}{ds} = -\kappa T + 0\cdot N + \tau B.$$
We can do this for all the otehr vectors. This gives us the \textit{Frenet Equations}:
\begin{align*}
    T' &= 0\cdot T + \kappa N + 0\cdot B,\\
    N' &= -\kappa T + 0 \cdot N + \tau B, \\
    B' &= 0\cdot T - \tau N + 0\cdot B.
\end{align*}

\begin{theorem}[Fundamental Theorem of Space Paths]
    Let $I \subseteq \R$ be an interval with basepoint $s_0 \in I$. Suppose $\tau : I \to \R$ is a $C^{k - 3}$ function, and $\kappa : I \to \R_{> 0}$ is a $C^{k-2}$ function. Then for any initial position $p_0$, initial velocity $v_0$, and initial normal $n_0$ in $\R^3$ such that $\norm{v_0} = \norm{n_0} = 1$ and $v_0 \dotp n_0 = 1$, there is a unique regular $C^k$ path $\gamma : I \to \R^3$ parametrized by arclength and satisfying the following conditions:
    $$\kappa_\gamma = \kappa, \qquad \tau_\gamma = \tau, \qquad \gamma(s_0) = p_0, \qquad \dot\gamma(s_0) = v_0, \qquad \ddot\gamma(s_0)/\norm{\ddot\gamma(s_0)} = n_0.$$
\end{theorem}

\begin{proof}
    If we look at the Frenet Equations and the given values in the statement of theorem, we can recognize that we have a 1st order linear IVP. By the Picard-Lindel√∂f Theorem, there is a unique solution $T,N,B : I \to \R^3$. Let's find $\gamma$ such that $T,N,B$ are the corresponding $T,N,B$ of $\gamma$. To do this, let's show that they form an orthonormal basis. By the Frenet Equations,
    \begin{align*}
        \frac{d}{ds}(T\dotp N) &= \kappa(N \dotp N) - \kappa(T\dotp T) + \tau(T \dotp B), \\
        \frac{d}{ds}(T\dotp N) &= \kappa(N \dotp B) - \tau(T\dotp N), \\
        \frac{d}{ds}(N\dotp B) &= -\kappa(T \dotp B) + \kappa(B\dotp B) - \tau(N \dotp N), \\
        \frac{d}{ds}(T\dotp T) &= 2\kappa(T\dotp T), \\
        \frac{d}{ds}(N\dotp N) &= -2\kappa (T \dotp N) + 2\tau(N \dotp B), \\
        \frac{d}{ds}(B\dotp B) &= -2\tau (N\dotp B).
    \end{align*} 
    This is a system of six first order ODEs with initial values $0,0,0,1,1,1$ which has a unique solution again. Since the constant functions $0,0,0,1,1,1$ also solve this IVP, then by uniqueness, 
    $$T\dotp N = T \dotp B = N\dotp B \equiv 0, \qquad T\dotp T = N \dotp N = B \dotp B \equiv 1.$$
    Therefore, $T,N,B$ form an orthogonal basis. \td
\end{proof}

\td

\end{document}